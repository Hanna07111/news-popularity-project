{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1YhKFGb-G37ayTdqOsDJa9RJlVGY5sj-f",
      "authorship_tag": "ABX9TyO/C7zfvejODA/v6PpMyiZI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanna07111/news-popularity-project/blob/main/XGboost_Ensemble_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZJGa_9KOjDwH",
        "outputId": "fece8f4a-53a2-4322-cc2d-4441b3558804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnUY_akyYPwW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/25-1 패턴인식 프로젝트/train_processed.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/25-1 패턴인식 프로젝트/test_processed.csv\")\n",
        "\n",
        "X = train_df.drop(columns=['id', 'y', 'shares'])\n",
        "y = train_df['y']\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### xgboost with best parameters"
      ],
      "metadata": {
        "id": "E33jOWZ7cggz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 최적 하이퍼파라미터로 모델 정의\n",
        "best_params = {\n",
        "    'n_estimators': 487,\n",
        "    'max_depth': 3,\n",
        "    'learning_rate': 0.022783546678795837,\n",
        "    'subsample': 0.9865934283784953,\n",
        "    'colsample_bytree': 0.6270846419992482,\n",
        "    'gamma': 0.8172927176529761,\n",
        "    'min_child_weight': 4,\n",
        "    'eval_metric': 'auc',\n",
        "    'random_state': 42,\n",
        "    'tree_method': 'hist',\n",
        "    # CPU 사용을 원하면 'hist'\n",
        "    # GPU를 사용하려면 'device': 'cuda' 추가\n",
        "    'device': 'cuda'\n",
        "}\n",
        "\n",
        "# 최종 모델 학습\n",
        "final_model = XGBClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터에 대해 예측 수행\n",
        "y_pred_valid = final_model.predict(X_valid)\n",
        "y_prob_valid = final_model.predict_proba(X_valid)[:, 1]  # 클래스 1일 확률\n",
        "\n",
        "# 성능 평가 (Accuracy, F1 Score, AUC)\n",
        "accuracy = accuracy_score(y_valid, y_pred_valid)\n",
        "f1 = f1_score(y_valid, y_pred_valid)\n",
        "auc = roc_auc_score(y_valid, y_prob_valid)\n",
        "\n",
        "# 세 가지 지표의 평균 계산\n",
        "mean_metric = (accuracy + f1 + auc) / 3\n",
        "\n",
        "# 성능 결과 출력\n",
        "print(\"Final Tuned Model Accuracy:\", accuracy)\n",
        "print(\"Final Tuned Model F1 Score:\", f1)\n",
        "print(\"Final Tuned Model AUC:\", auc)\n",
        "print(\"Mean Evaluation Metric (Accuracy + F1 + AUC) / 3:\", mean_metric)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olKsNXmhY87s",
        "outputId": "10545fcd-1031-410c-d77a-fcaa6221d08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Tuned Model Accuracy: 0.6765765765765765\n",
            "Final Tuned Model F1 Score: 0.6740807989105765\n",
            "Final Tuned Model AUC: 0.7298996619142015\n",
            "Mean Evaluation Metric (Accuracy + F1 + AUC) / 3: 0.6935190124671182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### xgboost with best parameters + random forest"
      ],
      "metadata": {
        "id": "2vBKouQ7ckVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#random forest와 앙상블\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "stack = StackingClassifier(\n",
        "    estimators=[('xgb', final_model), ('rf', rf_model)],\n",
        "    final_estimator=LogisticRegression()\n",
        ")\n",
        "\n",
        "stack.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터에 대해 예측 수행\n",
        "y_pred_stack = stack.predict(X_valid)\n",
        "y_prob_stack = stack.predict_proba(X_valid)[:, 1]  # 클래스 1일 확률\n",
        "\n",
        "# 성능 평가 (Accuracy, F1 Score, AUC)\n",
        "accuracy = accuracy_score(y_valid, y_pred_stack)\n",
        "f1 = f1_score(y_valid, y_pred_stack)\n",
        "auc = roc_auc_score(y_valid, y_prob_stack)\n",
        "\n",
        "# 세 가지 지표의 평균 계산\n",
        "mean_metric = (accuracy + f1 + auc) / 3\n",
        "\n",
        "# 성능 결과 출력\n",
        "print(\"Final Tuned Model Accuracy:\", accuracy)\n",
        "print(\"Final Tuned Model F1 Score:\", f1)\n",
        "print(\"Final Tuned Model AUC:\", auc)\n",
        "print(\"Mean Evaluation Metric (Accuracy + F1 + AUC) / 3:\", mean_metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2DiNVb3ZsZ0",
        "outputId": "e0d8d54e-d9d4-4a39-aeb5-438f13a61f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Tuned Model Accuracy: 0.6722972972972973\n",
            "Final Tuned Model F1 Score: 0.6716316858496953\n",
            "Final Tuned Model AUC: 0.7323438389996508\n",
            "Mean Evaluation Metric (Accuracy + F1 + AUC) / 3: 0.6920909407155479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tuning random forest (gridsearch, optuna)"
      ],
      "metadata": {
        "id": "I8rzSROBcq0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning with gridsearch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid = GridSearchCV(rf, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Best Score:\", grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb_Eox_6c05x",
        "outputId": "ccaf964e-6093-4ef1-c5f4-62e554427458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
            "Best Params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Best Score: 0.6544481981981981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning with optuna\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def rf_objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier(random_state=42, **params)\n",
        "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "    return score.mean()\n",
        "\n",
        "study_rf = optuna.create_study(direction='maximize')\n",
        "study_rf.optimize(rf_objective, n_trials=50)\n",
        "\n",
        "print(\"Best Score:\", study_rf.best_value)\n",
        "print(\"Best Params:\", study_rf.best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tfDDIm9DieP6",
        "outputId": "ba0c2618-60d9-42cb-ef42-7021b10b77ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-23 09:49:50,639] A new study created in memory with name: no-name-5874b19d-ef1e-403b-b45f-3f6579e2c2e4\n",
            "[I 2025-05-23 09:50:10,320] Trial 0 finished with value: 0.6529279279279279 and parameters: {'n_estimators': 166, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:50:26,790] Trial 1 finished with value: 0.6488175675675675 and parameters: {'n_estimators': 195, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:50:36,039] Trial 2 finished with value: 0.6454391891891892 and parameters: {'n_estimators': 202, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:50:57,029] Trial 3 finished with value: 0.6480855855855855 and parameters: {'n_estimators': 110, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:51:06,350] Trial 4 finished with value: 0.6441441441441441 and parameters: {'n_estimators': 122, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:51:36,141] Trial 5 finished with value: 0.6503941441441442 and parameters: {'n_estimators': 245, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:51:53,780] Trial 6 finished with value: 0.652195945945946 and parameters: {'n_estimators': 194, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:52:15,032] Trial 7 finished with value: 0.6522522522522523 and parameters: {'n_estimators': 145, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:52:27,546] Trial 8 finished with value: 0.6446509009009008 and parameters: {'n_estimators': 206, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:52:35,992] Trial 9 finished with value: 0.6483671171171171 and parameters: {'n_estimators': 159, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:53:07,602] Trial 10 finished with value: 0.6503378378378378 and parameters: {'n_estimators': 300, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:53:31,143] Trial 11 finished with value: 0.6512387387387387 and parameters: {'n_estimators': 148, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:53:51,231] Trial 12 finished with value: 0.6517454954954954 and parameters: {'n_estimators': 153, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:54:14,955] Trial 13 finished with value: 0.6515765765765765 and parameters: {'n_estimators': 169, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:54:25,505] Trial 14 finished with value: 0.6500563063063063 and parameters: {'n_estimators': 127, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:55:03,458] Trial 15 finished with value: 0.6526463963963964 and parameters: {'n_estimators': 242, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:55:27,478] Trial 16 finished with value: 0.6506193693693694 and parameters: {'n_estimators': 243, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.6529279279279279.\n",
            "[I 2025-05-23 09:55:54,175] Trial 17 finished with value: 0.6532657657657658 and parameters: {'n_estimators': 243, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 17 with value: 0.6532657657657658.\n",
            "[I 2025-05-23 09:56:36,657] Trial 18 finished with value: 0.6518581081081081 and parameters: {'n_estimators': 288, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 17 with value: 0.6532657657657658.\n",
            "[I 2025-05-23 09:56:49,972] Trial 19 finished with value: 0.6467342342342343 and parameters: {'n_estimators': 224, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 17 with value: 0.6532657657657658.\n",
            "[I 2025-05-23 09:57:12,367] Trial 20 finished with value: 0.6518581081081081 and parameters: {'n_estimators': 269, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 17 with value: 0.6532657657657658.\n",
            "[I 2025-05-23 09:57:50,737] Trial 21 finished with value: 0.6526463963963964 and parameters: {'n_estimators': 253, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 17 with value: 0.6532657657657658.\n",
            "[I 2025-05-23 09:58:13,082] Trial 22 finished with value: 0.6537162162162162 and parameters: {'n_estimators': 230, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 09:58:33,822] Trial 23 finished with value: 0.6484234234234235 and parameters: {'n_estimators': 222, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 09:58:55,275] Trial 24 finished with value: 0.6526463963963964 and parameters: {'n_estimators': 176, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 09:59:17,870] Trial 25 finished with value: 0.6503941441441442 and parameters: {'n_estimators': 222, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 09:59:47,108] Trial 26 finished with value: 0.6465090090090091 and parameters: {'n_estimators': 267, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:00:08,912] Trial 27 finished with value: 0.6522522522522523 and parameters: {'n_estimators': 183, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:00:23,875] Trial 28 finished with value: 0.6494932432432433 and parameters: {'n_estimators': 214, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:00:46,071] Trial 29 finished with value: 0.6489301801801802 and parameters: {'n_estimators': 191, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:01:11,271] Trial 30 finished with value: 0.6490990990990991 and parameters: {'n_estimators': 264, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:01:35,609] Trial 31 finished with value: 0.6511824324324325 and parameters: {'n_estimators': 233, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:02:07,432] Trial 32 finished with value: 0.6525337837837838 and parameters: {'n_estimators': 239, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:02:47,462] Trial 33 finished with value: 0.6509009009009009 and parameters: {'n_estimators': 256, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:03:02,423] Trial 34 finished with value: 0.6423986486486487 and parameters: {'n_estimators': 282, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:03:27,945] Trial 35 finished with value: 0.6528716216216216 and parameters: {'n_estimators': 208, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:03:51,847] Trial 36 finished with value: 0.6532094594594594 and parameters: {'n_estimators': 213, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:04:05,239] Trial 37 finished with value: 0.6457207207207206 and parameters: {'n_estimators': 193, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:04:25,680] Trial 38 finished with value: 0.6494932432432432 and parameters: {'n_estimators': 167, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:04:42,895] Trial 39 finished with value: 0.647972972972973 and parameters: {'n_estimators': 131, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:04:54,226] Trial 40 finished with value: 0.6492117117117118 and parameters: {'n_estimators': 102, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:05:17,405] Trial 41 finished with value: 0.6516328828828829 and parameters: {'n_estimators': 206, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:05:39,507] Trial 42 finished with value: 0.6510698198198198 and parameters: {'n_estimators': 215, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:06:05,732] Trial 43 finished with value: 0.6532657657657658 and parameters: {'n_estimators': 233, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:06:34,491] Trial 44 finished with value: 0.6523648648648649 and parameters: {'n_estimators': 231, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:06:58,927] Trial 45 finished with value: 0.6487612612612613 and parameters: {'n_estimators': 233, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:07:28,269] Trial 46 finished with value: 0.6516891891891892 and parameters: {'n_estimators': 252, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:07:53,781] Trial 47 finished with value: 0.6485923423423423 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:08:09,474] Trial 48 finished with value: 0.6479729729729731 and parameters: {'n_estimators': 183, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n",
            "[I 2025-05-23 10:08:30,860] Trial 49 finished with value: 0.6489864864864865 and parameters: {'n_estimators': 213, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.6537162162162162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.6537162162162162\n",
            "Best Params: {'n_estimators': 230, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### xgboost with best parameters + random forest with best parameters"
      ],
      "metadata": {
        "id": "YDtPlLGbi0T6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#random forest와 앙상블\n",
        "rf_model = RandomForestClassifier(**grid.best_params_)\n",
        "\n",
        "stack = StackingClassifier(\n",
        "    estimators=[('xgb', final_model), ('rf', rf_model)],\n",
        "    final_estimator=LogisticRegression()\n",
        ")\n",
        "\n",
        "stack.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터에 대해 예측 수행\n",
        "y_pred_stack = stack.predict(X_valid)\n",
        "y_prob_stack = stack.predict_proba(X_valid)[:, 1]  # 클래스 1일 확률\n",
        "\n",
        "# 성능 평가 (Accuracy, F1 Score, AUC)\n",
        "accuracy = accuracy_score(y_valid, y_pred_stack)\n",
        "f1 = f1_score(y_valid, y_pred_stack)\n",
        "auc = roc_auc_score(y_valid, y_prob_stack)\n",
        "\n",
        "# 세 가지 지표의 평균 계산\n",
        "mean_metric = (accuracy + f1 + auc) / 3\n",
        "\n",
        "# 성능 결과 출력\n",
        "print(\"Final Tuned Model Accuracy:\", accuracy)\n",
        "print(\"Final Tuned Model F1 Score:\", f1)\n",
        "print(\"Final Tuned Model AUC:\", auc)\n",
        "print(\"Mean Evaluation Metric (Accuracy + F1 + AUC) / 3:\", mean_metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNN3qLDQc7m0",
        "outputId": "8b323a09-60dc-4048-b057-61a2540b604e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Tuned Model Accuracy: 0.6711711711711712\n",
            "Final Tuned Model F1 Score: 0.6722047597665021\n",
            "Final Tuned Model AUC: 0.7314660050377035\n",
            "Mean Evaluation Metric (Accuracy + F1 + AUC) / 3: 0.6916139786584589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### xgboost with best parameters + rf + logistic regression"
      ],
      "metadata": {
        "id": "O8C9xvLGqsEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base models\n",
        "base_learners = [\n",
        "    ('xgb', XGBClassifier(**best_params)),\n",
        "    ('rf', RandomForestClassifier(**grid.best_params_)),\n",
        "    ('lr', LogisticRegression(max_iter=1000))\n",
        "]\n",
        "\n",
        "# Meta model\n",
        "meta_model = LogisticRegression()\n",
        "\n",
        "# Stacking\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,  # 내부에서 K-fold cross validation\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stack.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터에 대해 예측 수행\n",
        "y_pred_stack = stack.predict(X_valid)\n",
        "y_prob_stack = stack.predict_proba(X_valid)[:, 1]  # 클래스 1일 확률\n",
        "\n",
        "# 성능 평가 (Accuracy, F1 Score, AUC)\n",
        "accuracy = accuracy_score(y_valid, y_pred_stack)\n",
        "f1 = f1_score(y_valid, y_pred_stack)\n",
        "auc = roc_auc_score(y_valid, y_prob_stack)\n",
        "\n",
        "# 세 가지 지표의 평균 계산\n",
        "mean_metric = (accuracy + f1 + auc) / 3\n",
        "\n",
        "# 성능 결과 출력\n",
        "print(\"Final Tuned Model Accuracy:\", accuracy)\n",
        "print(\"Final Tuned Model F1 Score:\", f1)\n",
        "print(\"Final Tuned Model AUC:\", auc)\n",
        "print(\"Mean Evaluation Metric (Accuracy + F1 + AUC) / 3:\", mean_metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSEzSUrQqq80",
        "outputId": "50f9a1dd-eced-4f41-feb9-db761ca04795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Tuned Model Accuracy: 0.6702702702702703\n",
            "Final Tuned Model F1 Score: 0.6702702702702703\n",
            "Final Tuned Model AUC: 0.7313002190120654\n",
            "Mean Evaluation Metric (Accuracy + F1 + AUC) / 3: 0.6906135865175353\n"
          ]
        }
      ]
    }
  ]
}
